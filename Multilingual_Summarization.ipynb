{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifikimi i perdorimit te GPU NVIDIA CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mzu5FcJlmmZ3"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalimi i paketave te nevojshme per projektin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6e274fb",
    "outputId": "475370a6-5261-4f84-d395-e460df405a44"
   },
   "outputs": [],
   "source": [
    "!pip -q install -U \\\n",
    "  \"pandas==2.2.2\" \\\n",
    "  \"numpy>=2.0,<2.1\" \\\n",
    "  \"pyarrow>=15,<18\" \\\n",
    "  \"huggingface_hub>=0.33.5,<2.0\" \\\n",
    "  \"datasets==3.6.0\" \\\n",
    "  \"transformers>=4.41.0\" \\\n",
    "  \"accelerate>=0.33.0\" \\\n",
    "  \"evaluate>=0.4.2\" \\\n",
    "  \"rouge-score>=0.1.2\" \\\n",
    "  \"bert-score>=0.3.13\" \\\n",
    "  \"sentencepiece>=0.2.0\" \\\n",
    "  \"sacrebleu>=2.4.0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rifreskim i mjedisit punues pas instalimit te paketave te projektit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f66e28b0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pergaditja e listes se burimeve te te dhenava dhe modelit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9QniZFVwnezR"
   },
   "outputs": [],
   "source": [
    "import os, time, random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset, concatenate_datasets, get_dataset_config_names\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")\n",
    "import evaluate\n",
    "\n",
    "os.environ[\"FSSPEC_HTTP_TIMEOUT\"] = \"3600\"\n",
    "os.environ[\"HF_DATASETS_OFFLINE\"] = \"0\"\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "DATA_SOURCES = [\n",
    "    (\"GEM/wiki_lingua\", \"en\", \"en\", \"train\"),\n",
    "    (\"GEM/wiki_lingua\", \"de\", \"de\", \"train\"),\n",
    "    (\"GEM/wiki_lingua\", \"fr\", \"fr\", \"train\"),\n",
    "    (\"mlsum\", \"de\", \"de\", \"train\"),\n",
    "    (\"mlsum\", \"fr\", \"fr\", \"train\"),\n",
    "    (\"csebuetnlp/xlsum\", \"english\", \"en\", \"train\"),\n",
    "    (\"csebuetnlp/xlsum\", \"french\", \"fr\", \"train\"),\n",
    "]\n",
    "\n",
    "MAX_PER_SOURCE = 600\n",
    "TEST_SIZE = 0.05\n",
    "\n",
    "MIN_DOC_CHARS = 80\n",
    "MIN_SUM_CHARS = 10\n",
    "\n",
    "PREFIX = \"summarize\"\n",
    "MAX_INPUT_LENGTH = 384\n",
    "MAX_TARGET_LENGTH = 96\n",
    "\n",
    "MODEL_NAME = \"google/mt5-small\"\n",
    "OUT_DIR = \"./mt5-multilingual-summarizer\"\n",
    "FINAL_DIR = \"./mt5-multilingual-summarizer-final\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funksioni per shkarkimin e burimeve te te dhenava dhe standardizimi i te dhenave:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_load_dataset(name, config=None, split=\"train\", max_retries=3):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            ds = load_dataset(\n",
    "                name,\n",
    "                config,\n",
    "                split=split,\n",
    "                trust_remote_code=True,\n",
    "                download_mode=\"reuse_dataset_if_exists\",\n",
    "                verification_mode=\"no_checks\",\n",
    "            )\n",
    "            print(f\"Loaded {name}/{config}\")\n",
    "            return ds\n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                raise\n",
    "            time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_supported(dataset_name, config_name):\n",
    "    try:\n",
    "        return config_name in get_dataset_config_names(dataset_name)\n",
    "    except Exception:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_row(example):\n",
    "    doc = (\n",
    "        example.get(\"text\")\n",
    "        or example.get(\"article\")\n",
    "        or example.get(\"source\")\n",
    "        or example.get(\"document\")\n",
    "    )\n",
    "    summ = (\n",
    "        example.get(\"summary\")\n",
    "        or example.get(\"target\")\n",
    "        or example.get(\"highlights\")\n",
    "    )\n",
    "    return {\"document\": doc, \"summary\": summ}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid(example):\n",
    "    d, s = example[\"document\"], example[\"summary\"]\n",
    "    return (\n",
    "        isinstance(d, str) and isinstance(s, str)\n",
    "        and len(d) >= MIN_DOC_CHARS\n",
    "        and len(s) >= MIN_SUM_CHARS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lang(example, lang):\n",
    "    example[\"lang\"] = lang\n",
    "    return example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pergaditja e listes se dataseteve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_list = []\n",
    "\n",
    "for ds_name, cfg, lang, split in DATA_SOURCES:\n",
    "    if not config_supported(ds_name, cfg):\n",
    "        continue\n",
    "\n",
    "    ds = safe_load_dataset(ds_name, cfg, split)\n",
    "    ds = ds.select(range(min(len(ds), MAX_PER_SOURCE)))\n",
    "    ds = ds.map(standardize_row, remove_columns=ds.column_names)\n",
    "    ds = ds.filter(is_valid)\n",
    "    ds = ds.map(lambda x: add_lang(x, lang))\n",
    "\n",
    "    datasets_list.append(ds)\n",
    "\n",
    "min_len = min(len(ds) for ds in datasets_list)\n",
    "datasets_list = [ds.shuffle(seed=SEED).select(range(min_len)) for ds in datasets_list]\n",
    "\n",
    "full = concatenate_datasets(datasets_list).shuffle(seed=SEED)\n",
    "print(\"Total examples:\", len(full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ndarja e dataseteve per testim dhe evaluim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = full.train_test_split(test_size=TEST_SIZE, seed=SEED)\n",
    "train_ds = splits[\"train\"]\n",
    "eval_ds = splits[\"test\"]\n",
    "\n",
    "print(\"Train:\", len(train_ds), \"Eval:\", len(eval_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pergaditja e tokenizuesit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def preprocess(batch):\n",
    "    inputs = [f\"{PREFIX} ({l}): {d}\" for l, d in zip(batch[\"lang\"], batch[\"document\"])]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=MAX_INPUT_LENGTH,\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "    )\n",
    "\n",
    "    labels = tokenizer(\n",
    "        text_target=batch[\"summary\"],\n",
    "        max_length=MAX_TARGET_LENGTH,\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "    )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "train_tok = train_ds.map(preprocess, batched=True, remove_columns=train_ds.column_names)\n",
    "eval_tok  = eval_ds.map(preprocess,  batched=True, remove_columns=eval_ds.column_names)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=MODEL_NAME,\n",
    "    label_pad_token_id=-100,\n",
    ")\n",
    "\n",
    "print(\"Tokenized:\", len(train_tok), len(eval_tok))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trajnimi i modelit me parametrat e caktuar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(\"cuda\")\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=OUT_DIR,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=250,\n",
    "    save_steps=250,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "\n",
    "    learning_rate=1e-5,\n",
    "    warmup_ratio=0.05,\n",
    "    max_grad_norm=0.5,\n",
    "\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=3,\n",
    "\n",
    "    fp16=False,\n",
    "    logging_steps=25,\n",
    "    report_to=[],\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=eval_tok,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ruajtja e modelit per perdorime te ardhshme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(FINAL_DIR)\n",
    "tokenizer.save_pretrained(FINAL_DIR)\n",
    "print(\"Saved to:\", FINAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testimi i modelit pas trajnimit me metrikat ROUGE dhe BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(\"Loading metrics...\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "eval_batch_size = 4\n",
    "test_loader = DataLoader(eval_tok, batch_size=eval_batch_size, shuffle=False, collate_fn=data_collator)\n",
    "\n",
    "print(\"Starting generation on test set...\")\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        batch = {k: v.to(\"cuda\") for k, v in batch.items()}\n",
    "                generated_ids = model.generate(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            max_length=64,\n",
    "            num_beams=4,\n",
    "            length_penalty=2.0,\n",
    "            early_stopping=True,\n",
    "            no_repeat_ngram_size=3\n",
    "        )\n",
    "        \n",
    "        decoded_preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "        \n",
    "        labels = batch[\"labels\"].cpu().numpy()\n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "        \n",
    "        predictions.extend(decoded_preds)\n",
    "        references.extend(decoded_labels)\n",
    "\n",
    "print(\"\\nComputing ROUGE...\")\n",
    "rouge_results = rouge.compute(predictions=predictions, references=references)\n",
    "print(f\"ROUGE-1: {rouge_results['rouge1']:.4f}\")\n",
    "print(f\"ROUGE-2: {rouge_results['rouge2']:.4f}\")\n",
    "print(f\"ROUGE-L: {rouge_results['rougeL']:.4f}\")\n",
    "\n",
    "print(\"\\nComputing BERTScore (this takes a moment)...\")\n",
    "bert_results = bertscore.compute(\n",
    "    predictions=predictions, \n",
    "    references=references, \n",
    "    lang=\"en\",\n",
    "    model_type=\"distilbert-base-multilingual-cased\", \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"BERTScore F1 (Mean): {np.mean(bert_results['f1']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gjenerimi i permbledhjeve ne test cases te ndryshme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from transformers import MT5ForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MT5ForConditionalGeneration.from_pretrained(FINAL_DIR).to(device)\n",
    "model.eval()\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(FINAL_DIR, use_fast=True)\n",
    "\n",
    "TRAIN_PREFIX = \"summarize\"\n",
    "\n",
    "def capitalize_first_letter(text: str) -> str:\n",
    "    for i, c in enumerate(text):\n",
    "        if c.isalpha():\n",
    "            return text[:i] + c.upper() + text[i+1:]\n",
    "    return text\n",
    "\n",
    "def summarize(text, num_beams=6, max_new_tokens=96):\n",
    "    inputs = tok(\n",
    "        TRAIN_PREFIX + text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_INPUT_LENGTH,\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ids = model.generate(\n",
    "            **inputs,\n",
    "            num_beams=num_beams,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            min_new_tokens=20,\n",
    "            length_penalty=1.1,\n",
    "            repetition_penalty=1.1,\n",
    "            no_repeat_ngram_size=3,\n",
    "            early_stopping=True,\n",
    "        )\n",
    "\n",
    "    s = tok.decode(ids[0], skip_special_tokens=True)\n",
    "\n",
    "    s = s.replace(\"▁\", \" \")\n",
    "    s = re.sub(r\"<extra_id_\\d+>\", \"\", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    s = re.sub(r\"^(in English:|en français:|auf Deutsch zusammen:)\\s*\", \"\", s, flags=re.IGNORECASE).strip()\n",
    "\n",
    "    return capitalize_first_letter(s)\n",
    "\n",
    "test_cases = [\n",
    "    (\"EN\", \"\"\"Researchers at a university lab reported a new battery design that charges faster and lasts longer.\n",
    "They said the prototype uses a modified electrolyte that reduces degradation. Independent testing is still limited,\n",
    "but early results suggest improved cycle life and better performance in cold temperatures.\"\"\"),\n",
    "\n",
    "    (\"EN\", \"\"\"A city council debated a new transportation plan that would add dedicated bus lanes, expand bike routes,\n",
    "and increase parking fees downtown. Supporters argued it would reduce traffic and emissions, while critics warned\n",
    "about impacts on small businesses and push traffic into residential areas.\"\"\"),\n",
    "\n",
    "    (\"FR\", \"\"\"Selon un rapport récent, la hausse des températures aggrave les épisodes de pollution dans plusieurs grandes villes.\n",
    "Les experts recommandent de renforcer les transports publics, de limiter la circulation lors des pics et d’améliorer\n",
    "la surveillance de la qualité de l’air.\"\"\"),\n",
    "\n",
    "    (\"FR\", \"\"\"Une entreprise a annoncé le lancement d’un service de traduction automatique destiné aux PME.\n",
    "Le produit promet une meilleure prise en compte du contexte et des expressions idiomatiques, mais certains spécialistes\n",
    "rappellent que les erreurs restent possibles dans les domaines juridiques et médicaux.\"\"\"),\n",
    "\n",
    "    (\"DE\", \"\"\"Mehrere Regionen meldeten ungewöhnlich hohe Temperaturen und eine Zunahme von Starkregenereignissen.\n",
    "Forschende erklären, dass wärmere Luft mehr Feuchtigkeit speichern kann, was die Intensität von Niederschlägen erhöht.\n",
    "Kommunen investieren in bessere Entwässerung, Hitzeschutzpläne und Frühwarnsysteme.\"\"\"),\n",
    "\n",
    "    (\"DE\", \"\"\"Ein großer Einzelhändler kündigte an, Filialen umzubauen, um mehr Platz für Abholstationen und Rücksendungen zu schaffen.\n",
    "Das Unternehmen reagiert damit auf den wachsenden Onlinehandel. Kritiker befürchten längere Wartezeiten durch weniger Personal.\"\"\"),\n",
    "\n",
    "    (\"EN\", \"\"\"Cybersecurity firms have observed a sharp rise in phishing attacks targeting remote workers via SMS and social media.\n",
    "Hackers are using AI tools to craft convincing messages that mimic company executives or IT support.\n",
    "Experts advise corporations to implement stricter multi-factor authentication and regular employee training to combat this threat.\"\"\"),\n",
    "\n",
    "    (\"EN\", \"\"\"The housing market has cooled significantly as central banks raised interest rates to combat inflation.\n",
    "Real estate agents report that homes are sitting on the market longer, and price reductions are becoming common.\n",
    "While this makes buying harder for first-time owners due to mortgage costs, it may eventually stabilize skyrocketing property values.\"\"\"),\n",
    "\n",
    "    (\"EN\", \"\"\"Biologists are sounding the alarm over the rapid decline of wild bee populations due to pesticide use and habitat loss.\n",
    "Since bees are responsible for pollinating a third of the food we eat, their disappearance could threaten global food security.\n",
    "Conservationists are urging farmers to plant wildflower strips and reduce chemical usage to support pollinators.\"\"\"),\n",
    "\n",
    "    (\"EN\", \"\"\"Major streaming services are introducing ad-supported subscription tiers and cracking down on password sharing to boost revenue.\n",
    "This shift comes as the market becomes saturated and production costs for original content soar.\n",
    "Subscribers have expressed mixed reactions, with some welcoming cheaper options while others threaten to cancel memberships.\"\"\"),\n",
    "\n",
    "    (\"FR\", \"\"\"Le projet du Grand Paris Express, qui prévoit l'extension massive du réseau de métro, transforme déjà la banlieue parisienne.\n",
    "De nouvelles gares sortent de terre, attirant les promoteurs immobiliers et faisant grimper les prix des logements aux alentours.\n",
    "Les élus locaux espèrent que ce réseau réduira les inégalités territoriales en désenclavant des quartiers jusqu'ici mal desservis.\"\"\"),\n",
    "\n",
    "    (\"FR\", \"\"\"La consommation de produits biologiques a enregistré une baisse inédite cette année, frappée par l'inflation alimentaire.\n",
    "Les consommateurs, soucieux de leur pouvoir d'achat, se tournent vers des alternatives moins coûteuses ou les marques de distributeurs.\n",
    "Les agriculteurs bio demandent une aide d'urgence à l'État pour éviter des faillites en cascade dans la filière.\"\"\"),\n",
    "\n",
    "    (\"FR\", \"\"\"Le festival de Cannes a ouvert ses portes dans un climat de polémique concernant la place des plateformes de streaming au cinéma.\n",
    "Alors que certains réalisateurs défendent l'expérience unique de la salle obscure, d'autres estiment que le streaming permet de financer des œuvres audacieuses.\n",
    "Le jury devra trancher entre tradition et modernité lors de la remise de la Palme d'or.\"\"\"),\n",
    "\n",
    "    (\"DE\", \"\"\"Die Debatte über die Vier-Tage-Woche gewinnt in Deutschland an Fahrt, da Pilotprojekte positive Ergebnisse zeigen.\n",
    "Befürworter argumentieren, dass weniger Arbeitszeit die Produktivität steigert und krankheitsbedingte Ausfälle reduziert.\n",
    "Arbeitgeberverbände warnen jedoch, dass dies in Zeiten des Fachkräftemangels die Wirtschaft schwächen und Kosten erhöhen könnte.\"\"\"),\n",
    "\n",
    "    (\"DE\", \"\"\"Wegen zahlreicher Baustellen und technischer Störungen hat die Deutsche Bahn erneut ihre Pünktlichkeitsziele verfehlt.\n",
    "Der Konzern kündigte an, das Schienennetz in den kommenden Jahren grundlegend zu sanieren, was zunächst zu noch mehr Sperrungen führen wird.\n",
    "Verkehrsminister fordern ein besseres Baustellenmanagement, um die Geduld der Fahrgäste nicht überzustrapazieren.\"\"\"),\n",
    "\n",
    "    (\"DE\", \"\"\"Der Trend zu sogenannten Balkonkraftwerken boomt, da immer mehr Mieter ihren eigenen Solarstrom produzieren wollen.\n",
    "Vereinfachte bürokratische Regeln und sinkende Preise für Solarmodule haben die Nachfrage sprunghaft ansteigen lassen.\n",
    "Energieexperten sehen darin einen wichtigen, wenn auch kleinen, Baustein für die Energiewende in privaten Haushalten.\"\"\"),\n",
    "\n",
    "    (\"FR\", \"\"\"Les viticulteurs du sud de la France font face à des vendanges de plus en plus précoces en raison du réchauffement climatique.\n",
    "La chaleur intense modifie le taux de sucre et l'acidité du raisin, obligeant les producteurs à adapter leurs techniques de vinification.\n",
    "Certains envisagent même de planter de nouvelles variétés de cépages plus résistantes à la sécheresse.\"\"\"),\n",
    "\n",
    "    (\"DE\", \"\"\"Archäologen haben in Bayern ein gut erhaltenes Schwert aus der Bronzezeit entdeckt, das über 3000 Jahre alt ist.\n",
    "Der Fund gilt als Sensation, da die Waffe noch ihren metallischen Glanz besitzt und reich verziert ist.\n",
    "Historiker erhoffen sich dadurch neue Erkenntnisse über die Handwerkskunst und Handelsbeziehungen der damaligen Zeit.\"\"\"),\n",
    "\n",
    "]\n",
    "\n",
    "for lang, doc in test_cases:\n",
    "    print(f\"\\n[{lang}]\")\n",
    "    print(\"DOCUMENT:\", doc)\n",
    "    print(\"SUMMARY:\", summarize(doc))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
